\documentclass[letter,11pt]{article}
\usepackage{times}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}

\usepackage{float}% gives float option 'H' to stop floats from floating

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{bbm,eufrak}
\usepackage{undertilde}
\usepackage{hyperref}
\usepackage[version=4]{mhchem}

%\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\mat}[1]{\underline{\mathbf{#1}}}
\newcommand{\trans}[1]{{#1}^{\mathsf{T}}}


\newcommand{\scmat}[1]{\vec{\utilde{#1}}}
\newcommand{\cvec}[1]{\utilde{#1}}
\newcommand{\svec}[1]{\vec{#1}}

\newcommand{\laeq}[1]{\label{eqn:#1}}
\newcommand{\refeq}[1]{eq.~\ref{eqn:#1}}

%\newcommand{\MM}{\sum_{j=1}^N m_j^2}
\newcommand{\MM}{\mathfrak{M_2}}
\newcommand{\Rcm}{\svec{R}_{\textrm{c.m.}}}
\newcommand{\dotRcm}{\dot{\svec{R}}_{\textrm{c.m.}}}


\title{Center of mass invariant geodesics for heterogeneous systems}
\author{Vale Cofer-Shabica}
\date{\today}

\setlength{\parskip}{1.5ex}
\setlength{\parindent}{0em}

\begin{document}

\maketitle


\section{Why geodesics for photodissociation?}
One of the techniques our group uses to understand chemical systems is identifying the geodesics (or shortest paths) through an energy landscape with the \emph{inherent dynamics} of the system. Inherent dynamics describe the dominant thoroughfares of configuration space---the major motions during a chemical or physical transformation. How might we find these dynamics, so definitionally different from molecular dynamics? First, we need some way to partition configuration space into allowed and disallowed regions and then we need a strategy to traverse them and identify these major routes.

To partition the space, We take the perspective of the potential energy landscape ensemble \cite{wang:2007:pele}, which admits all configurations, $\cvec{R}$, such that the potential, $V$, is less than some landscape energy, $E_L$.
\[
  V(\cvec{R}) \le E_L
\]

How do we compute dynamics in this system? Classical mechanics can be formulate in terms of the principle of least action, minimize:
\[
  S = \int_{0}^{t}d\tau\left( T - V \right)
\]
where $T$ is the kinetic energy. From the landscape ensemble picture, we minimize a similar integral subject to the landscape energy constraint:
\begin{equation} \laeq{peleS}
  I = \int_{0}^{t}d\tau\left( T \right) \quad \textrm{s.t.} \quad   V(\cvec{R}(\tau)) \le E_L
\end{equation}
Minimization of objects such as these is the work of the calculus of variations, to which we now turn.

\begin{table}
  \begin{center}
    \begin{tabular}{c l}
      \textbf{Symbol} & \textbf{Description} \\
      \hline
      $T,V$ & respectively, the kinetic and potential energy \\
      $\tau$ & arbitrary progress, time-like variable \\
      $\svec{R}$ & real-space, lab-frame vector \\
      $\cvec{R}$ & configuration-space vector, lab-frame \\
      $\svec{r}$ & real-space vector, internal coordinates\\
      $\Rcm$ & system center-of-mass, lab-frame\\
      $\dot{\svec{R}}$ & $\tau$-derivative of a vector\\
      $N$ & number of total atoms in the system \\
      $j,k$ & subscripts running over atoms: $1 \ldots N$ \\
      $\mu,\nu,\alpha,\gamma$ & subscripts running over real-space coordinates: $x,y,z$ \\
      $\alpha$ & alternately, a small parameter\\
      ${\left( \cvec{\xi} \right)}_{j\alpha}$ & component of $\cvec{\xi}$ corresponding to the $\alpha\textrm{th}$ coordinate of the $j\textrm{th}$ atom\\
      $\delta_{\mu,\nu}$ & Kronecker delta; 1 for $\mu=\nu$, 0 otherwise \\
      $\mathbbm{1}$ & unit matrix; dimensionality from context\\
      $\hat{u}$ & unit vector; dimensionality from context
    \end{tabular}
  \end{center}
  \caption{\label{tab:notation}List of symbols and notation conventions}
\end{table}

\section{The calculus of variations}
This section follows~\cite{goldstein:1980} with modifications suggested by R.M.S.

Using calculus to find the extrema of a function (\emph{e.g.}: $h(x)$) is a familiar operation. By equating the derivative of $h(x)$ with $0$, we locate values of $x$ for which $h(x)$ is unchanging or stationary. The problem treated by the calculus of variations is analogous. We seek to extremize an object that takes a \emph{function} or a path as its argument. That is, we find some path such that the object is stationary with respect to variations in that function.

From \refeq{peleS}, we seek to minimize an integral over kinetic energy, which in general is a function of coordinates and their derivatives. Working in one dimension\footnote{This procedure extends to systems with an arbitrary number of degrees of freedom}, we seek to find the path $R(\tau)$ that extremizes:
\begin{equation}\laeq{J}
  J = \int_{0}^{t}d\tau f \left(R, \dot{R} \right)
\end{equation}
That is, we seek $R(\tau)$ such that $J$ is unchanged for infinitesimal variations in $R$. We can represent the paths neighboring the correct path, $R(\tau)$ by adding arbitrary function, $\eta(\tau)$ in proportion to a small variable parameter, $\alpha$:
\begin{equation}\laeq{eta}
  R(\tau,\alpha) = R(\tau) + \alpha\eta(\tau)
\end{equation}
As we are interested in $R$ such that it connects $R(0)$ to $R(t)$, we require that:
\begin{equation}\laeq{eta:bounds}
  \eta(0)=\eta(t)=0
\end{equation}
$J$ in \refeq{J} is now a function of $\alpha$ as well:
\begin{equation}\laeq{Ja}
  J(\alpha) = \int_{0}^{t}d\tau f \left(R(\tau,\alpha), \dot{R}(\tau, \alpha) \right)
\end{equation}
From the above, we see that the requirement for stationary $J$ takes the following familiar form:
\begin{equation}
  0 = {\left. \frac{d J}{d \alpha} \right|}_{\alpha=0}
\end{equation}
We can bring the $\alpha$ derivative inside the integral in \refeq{Ja} and applying the chain rule, we have:
\begin{equation*}
  \frac{d J}{d \alpha} = \int_{0}^{t}d\tau \left( \frac{\partial f}{\partial R}\frac{\partial R}{\partial \alpha} + \frac{\partial f}{\partial \dot{R}}\frac{\partial \dot{R}}{\partial \alpha} \right)
\end{equation*}
From \refeq{eta}, we have that $\frac{\partial R}{\partial \alpha} = \eta$, the arbitrary function of $\tau$. Which leaves:
\begin{equation}\laeq{J:1}
  \frac{d J}{d \alpha} = \int_{0}^{t}d\tau \left( \frac{\partial f}{\partial R}\eta + \frac{\partial f}{\partial \dot{R}}\frac{\partial \dot{R}}{\partial \alpha} \right)
\end{equation}
Consider the second term in the integral:
\begin{equation*}
  \int_{0}^{t}d\tau\frac{\partial f}{\partial \dot{R}}\frac{\partial \dot{R}}{\partial \alpha} = \int_{0}^{t}d\tau\frac{\partial f}{\partial \dot{R}}\frac{\partial^2 R}{\partial \alpha \partial \tau}
\end{equation*}
This expression is susceptible by integration by parts, which takes the following general form:
\begin{equation*}
  \int_a^b u dv = {\left. uv \right|}_a^b - \int_a^b v du
\end{equation*}
Identify:
\begin{center}
  \vspace{-\baselineskip}
  \begin{tabular}{c c c}
    $\begin{aligned}
      u  &= \frac{\partial f}{\partial \dot{R}} \\
      dv &= \frac{\partial^2 R}{\partial \alpha \partial \tau} d\tau
    \end{aligned}$
& \hspace{3em} &
    $\begin{aligned}
      du &= \frac{d}{d\tau} \left( \frac{\partial f}{\partial \dot{R}} \right) \\
      v  &= \frac{\partial R}{\partial \alpha}=\eta 
    \end{aligned}$
  \end{tabular}
\end{center}
Re-arranging leaves us with:
\begin{equation*}
  \int_{0}^{t}d\tau\frac{\partial f}{\partial \dot{R}}\frac{\partial \dot{R}}{\partial \alpha} = {\left. \frac{\partial f}{\partial \dot{R}} \eta \right|}_0^t - \int_{0}^{t}d\tau \frac{d}{d\tau} \left( \frac{\partial f}{\partial \dot{R}} \right) \eta
\end{equation*}
Because of the bounds on $\eta$ (recall \refeq{eta:bounds}) the surface terms vanish. Inserting the above into \refeq{J:1} gives:
\begin{equation}\laeq{J:2}
  {\left. \frac{d J}{d \alpha} \right|}_{\alpha=0} = 
  \int_{0}^{t}d\tau \left[ \frac{\partial f}{\partial R} - \frac{d}{d\tau} \left( \frac{\partial f}{\partial \dot{R}} \right) \right] \eta = 0
\end{equation}
where evaluating the derivative at $\alpha=0$ gives $R$ and $\dot{R}$ as functions of $\tau$ alone. Since $\eta$ is an arbitrary function, the integral is stationary \emph{only} if
\begin{equation}\laeq{G2-11}
  \frac{\partial f}{\partial R} - \frac{d}{d\tau}\frac{\partial f}{\partial\dot{R}}  = 0
\end{equation}
which gives the conditions on $R$ to minimize $J$. Notice that inserting the Lagrangian for $f$ yields Lagrange's equations of motion.

\subsection{Minimizing \refeq{peleS}}
For an $N$ particle system, with labels $j=1 \ldots N$, in a Cartesian coordinate system with $\mu = x,y,z$, the kinetic energy can be written as:
\begin{equation}
  T = \sum_{j,\mu} \frac{1}{2} m_j \dot{R}_{j\mu}^2
\end{equation}
where $\dot{\svec{R}}_{j} = \frac{d\svec{R}_{j}}{d\tau}$. Inserting $T$ into \refeq{peleS} gives:
\begin{equation}
   I = \int_{0}^{t}d\tau\left( \sum_{j,\mu} \frac{1}{2} m_j \dot{R}_{j\mu}^2 \right)
\end{equation}
Identifying the sum as $f$ in \refeq{G2-11}, we proceed and can extremize the function in terms of each of its independent (there are no cross-terms) variables, $\{\dot{R}_{j\mu}\}$,  finding:
\begin{equation}
  \ddot{R}_{j\mu} = 0
\end{equation}
which, when integrated, yields the equation for a straight line (and the geodesic):
\begin{equation}\laeq{straightLine}
  R_{j\mu}(\tau) = R_{j\mu}(0) \left( 1-\frac{\tau}{t} \right) + R_{j\mu}(t)\left( \frac{\tau}{t} \right)
\end{equation}
this amounts to linearly interpolating between $R_{j\mu}(0)$ and $R_{j\mu}(t)$ in time $t$ for each of the coordinates, $\{R_{j\mu}\}$.

\section{Geodesics}
In the previous section we found that minimizing the integral in \refeq{peleS} gave the equation for a straight line---the shortest path in a Cartesian space. We can also motivate the notion of shortest path as follows. Begin from \refeq{peleS}:
\[
    I = \int_{0}^{t}d\tau\left( T \right)
\]
Working in a system with homogeneous masses, $m$, inserting the kinetic energy yields:
\begin{equation}\laeq{geodesic-1}
  I = \int_{0}^{t}d\tau\left( \frac{1}{2}m {\dot{\cvec{R}}}^2\right)
\end{equation}
Note that the extremization of any quantity of the form:
\begin{equation}
  I = \int f(x)dx
\end{equation}
can also be effected by extremizing 
\begin{equation}
  I' = \int H(f(x))dx
\end{equation}
where $H(x)$ is a function with a strictly positive derivative and  whose domain includes the range of $f(x)$. Suppose we take for such a function, $H(x)=\sqrt{2x}$, \refeq{geodesic-1} becomes:
\begin{align}
  I' &= \int_{0}^{t}d\tau {\left(m {\dot{\cvec{R}}}^2\right)}^{1/2} \\
  &= m^{1/2} \int_{0}^{t}d\tau {\left({\frac{d \cvec{R} }{d\tau}}^2\right)}^{1/2} \\
  &= m^{1/2} \int_{0}^{t} {d\tau^2 \left({\frac{d \cvec{R} }{d\tau}}^2\right)}^{1/2} \\
  &= m^{1/2} \int_{0}^{t} \left| d \cvec{R} \right| \\
  &= m^{1/2} \int_{0}^{t} ds = \ell
\end{align}
where $ds$ is an element of path length and $\ell$ is a mass-weighted length, found by integrating over the path-length element. In this case, it is clear that we quite literally minimize the path length, which, by definition, yields a geodesic.


\subsection{Why impose a constraint?}
While our intuition may be that center of mass translation \emph{should} increase the length of a path between two points in configuration space which have the same center of mass, we can show explicitly that this is indeed the case.

The kinematic length defined as per~\cite{wang:2007:geodesics} (or found via another route) is:
\begin{equation}\label{eqn:klen}
\ell = \int d\tau\sqrt{2 T(\tau)}
\end{equation}
where $T(\tau)$ is the kinetic energy as a function of progress along the path for an $N$ particle system is defined as above:
\begin{equation}
  T = \sum_{j=1}^{N} \frac{1}{2} m_j {\dot{\svec{R}}_j}^2
\end{equation}
We can introduce a coordinate transformation to separate center of mass motion from internal coordinates as follows:
\begin{equation}\laeq{Rcm}
  \Rcm \equiv \frac{\sum^{N}_{j=1}m_j \svec{R}_j}{\sum^{N}_{j=1}m_j} \equiv \frac{1}{M} \sum^{N}_{j=1}m_j \svec{r}_j
\end{equation}
where $m_j$ is the mas of the $j$th particle. The internal coordinates are then:
\begin{equation}\laeq{internalCoors}
  \svec{r}_j \equiv \svec{R}_j - \Rcm
\end{equation}
Note that our system of $3N$ degrees of freedom is now specified with $3N + 3$ coordinates.

We can now write the kinetic energy as:
\begin{align}
  T &= \frac{1}{2}\sum_{j=1}^{N} m_{j} {\left(\dot{\svec{r}}_{j} + \dotRcm \right)}^2 \\
    &= \frac{1}{2}\sum_{j=1}^{N} m_{j} {\dot{\svec{r}}_{j}}^2 + \frac{1}{2}M {\dotRcm}^{2} \laeq{cmT}
\end{align}
The cross-terms vanish (as expected) because:
\begin{align}
  \sum_{j=1}^{N} m_{j} \dot{\svec{r}}_j \cdot \dotRcm &= \left[ \sum_{j=1}^{N} m_{j} \dot{\svec{r}}_j \right] \cdot \dotRcm \\
  &= \left[\sum_{j=1}^N m_j \left( \dot{\svec{R}}_j - \dotRcm \right) \right] \cdot \dotRcm\\
  &= \left[\sum_{j=1}^N m_j \dot{\svec{R}}_j - \sum_{j=1}^N m_j \dotRcm \right] \cdot \dotRcm \\
  &= \left[ M\dotRcm - M\dotRcm \right] \cdot \dotRcm \\
  &= \svec{0} \cdot \dotRcm = 0
\end{align}

Inserting \refeq{cmT} into our length expression, \refeq{klen},gives:
\begin{equation}
  \ell = \int d\tau {\left[ \sum_{j=1}^{N} m_{j} {\dot{\svec{r}}_{j}}^2 + M {\dotRcm}^{2} \right]}^{1/2}
\end{equation}
bringing $d\tau$ inside the root allows us to cancel the time derivatives and leaves us with a function of length elements, or displacements:
\begin{equation}
  \ell = \int {\left[ \sum_{j=1}^{N} m_{j} {\left(d{\svec{r}}_{j} \right)}^2 + M {\left( d\Rcm \right)}^{2} \right]}^{1/2}
\end{equation}
Both terms are guaranteed positive and so any path for which $\left( d\Rcm \right)$ is finite will be longer than if it were 0.

We also could have arrived at the same conclusion by noting the form of \refeq{straightLine}. Our solution interpolates between specified boundary-points. If some of the boundary values are identical, \emph{e.g.}: $\Rcm(0) = \Rcm(t)$, then \refeq{straightLine} gives $\Rcm(\tau) = \Rcm(0)$ for all $\tau$. This is indeed the case for translationally invariant potentials and as such our geodesics should preserve the center of mass. By the form of \refeq{straightLine}, we know that straight-line paths will not perturb the center of mass. To actually compute such paths we discretize \refeq{straightLine} as follows:
\begin{equation}\laeq{step:free}
  \cvec{R}^{(t+1)} = \cvec{R}^{(t)} + \delta R \frac{\cvec{R}_f - \cvec{R}^{(t)}}{\left| \cvec{R}_f - \cvec{R}^{(t)} \right|}
\end{equation}
Where $\delta R$ is a small (relative to features of the landscape) step-size and the walk is carried out in the lab-frame, $\{\svec{R}_j\}$

\section{Geodesics around objects}
So far we have dealt only with the first part of \refeq{peleS}, which read:
\begin{equation}
  I = \int_{0}^{t}d\tau\left( T \right) \quad \textrm{s.t.} \quad V(\cvec{R}(\tau)) \le E_L
\end{equation}
namely the minimization of the action integral. The second part requires us to satisfy a non-holonomic constraint. The form of the solution is suggested by the Kuhn-Tucker theorem\cite{kuhntucker:1951}, which indicates that our desired solution will be the union of paths in the absence of a constraint and those where strict equality holds. When the straight-line motion in \refeq{step:free} sends the system into a region violating the landscape criterion, $V(\cvec{r}) > E_L$, we need a way to proceed.

\subsection{Vanilla Newton-Raphson}
The Kuhn-Tucker theorem suggests that we must closely trace the boundaries of the obstacles specified by $V(\cvec{R}(\tau)) \le E_L$. We aim, therefore to take the most efficient path out of the obstacle. When the procedure described in \refeq{step:free} moves the system such that $V(\cvec{R}(\tau)) > E_L$, we need a way back to the boundary. That is, we seek the nearest solution to $V(\cvec{R}(\tau)) = E_L$. A classic strategy for solving this problem is a Newton-Raphson root search.

Here, we expand the function of interest to first order and run downhill:
\begin{align}\laeq{expansion}
  V(\cvec{R}) \approx  V(\cvec{R}_0) + \left. \cvec{\nabla}V\right|_{\cvec{R}_0} \cdot (\cvec{R} - \cvec{R}_0) = E_L
\end{align}
Where $\cvec{R}_0$ was the first offending step in \refeq{step:free}. We make the \emph{guess} that heading downhill via the steepest path will be optimal; this suggests a solution of the form:
\begin{equation}\laeq{NR:vanilla}
  (\cvec{R} - \cvec{R}_0) = C \left. \cvec{\nabla} V\right|_{\cvec{R}_0} \equiv \Delta\cvec{R}
\end{equation}
Which immediately yields the solution:
\[
  C = \frac{E_L - V(\cvec{R}_0)}{{\left| \left. \cvec{\nabla} V\right|_{\cvec{R}_0} \right|}^2}
\]
This procedure is iterated until the boundary is found.

\subsubsection{What of the center-of-mass?}
While it may look like \refeq{NR:vanilla} renders our problem solved, we still need to contend with possible displacements to the center of mass. Using \refeq{Rcm} we can compute the change in the position of the center of mass:
\begin{equation}\laeq{deltaRcm}
  \Delta\Rcm = \frac{C}{M} \sum_{j=1}^N m_j {\left(\left. \overrightarrow{\nabla V} \right|_{\cvec{R}_0} \right)}_j %\stackrel{?}{=} 0
\end{equation}
Where ${\left(\left. \overrightarrow{\nabla V} \right|_{\cvec{R}_0} \right)}_j$ is the component of the $\left. \cvec{\nabla} V \right|_{\cvec{R}_0}$ corresponding to the $j$th center and is the negative of the force acting on that body.

\paragraph{Proving that \refeq{deltaRcm} is 0} in general would  be quite difficult (particularly given that it is not), but invalidating it requires only one counter-example. All the problems treated by the group's analysis of geodesics to date (March 2016), involve translationally invariant potentials, so let us confine our attention to a particularly simple one: the pair-potential for two mutually interacting centers. The form of our potential is then:
\begin{equation}
V = u(\left|\svec{r}_1 - \svec{r}_2\right|)
\end{equation}
Taking $\svec{r}_{12} = \svec{r}_1 - \svec{r}_2$ We compute the gradient in \refeq{deltaRcm}, arriving at:
\begin{equation} \laeq{counterDerivative}
\renewcommand*{\arraystretch}{1.5}
\cvec{\nabla}V =
\begin{pmatrix}
\frac{\partial u}{\partial \svec{r}_{12}} \\
\frac{\partial u}{\partial \svec{r}_{21}}
\end{pmatrix}
\end{equation}
Using $\svec{r}_{12} = - \svec{r}_{21}$ and inserting \refeq{counterDerivative} into \refeq{deltaRcm} gives
\begin{equation}
  \Delta\Rcm = \frac{C}{M}\frac{\partial u}{\partial \svec{r}_{12}} \left( m_1 -  m_2 \right) 
\end{equation}
We see that \refeq{deltaRcm} is finite for  for $m_1 \neq m_2$. Therefore our na{\"\i}ve root search does \emph{not} preserve the center of mass with heterogeneous masses (and therefore would erroneously lengthen the path). On the flip-side, \refeq{deltaRcm} \emph{is} 0 when the masses are the same. It can be shown that this is alto so for a sums of such pair potentials with equal masses and therefore the group's previous results are safe from this issue.

\subsection{Newton-Raphson with a constraint}
Suppose we modify \refeq{expansion} to respect a constraint. After all \refeq{NR:vanilla} was based on a guess about following the gradient. If, instead, we chose to follow a path constrained to be \emph{parallel} to some direction, $\hat{n}$, \refeq{NR:vanilla} would have the following form:
\begin{equation}\laeq{NR:parallel}
  (\cvec{R} - \cvec{R}_0) = C \hat{n}
\end{equation}
and inserting into \refeq{expansion} would yield:
\begin{align}
  V(\cvec{R}) \approx  V(\cvec{R}_0) + C \left. \cvec{\nabla}V\right|_{\cvec{R}_0} \cdot \hat{n} = E_L
\end{align}
Solving for $C$ yields:
\[
  C = \frac{E_L - V(\cvec{R}_0)}{\left. \cvec{\nabla} V\right|_{\cvec{R}_0} \cdot \hat{n}}
\]
While this is well an good, it doesn't quite solve our problem. We need to be able to impose a constraint that is \emph{orthogonal} to some directions, those of center of mass motion. What if we follow the path of steepest descent subject to the constraint that it is orthogonal to some configuration-space vector which would moved the center of mass, $\hat{\xi}$?

\paragraph{To construct such a step we take a brief detour to discuss dyads.} The following treatment uses the notation of real-space vectors, but is applicable to vectors of arbitrary dimension (such as our configuration space vectors). This treatment is reprised and expanded in~\cite{simmonds:1982}, which was recommended to me by R.M.S. and which I found quite useful.

A dyad (or dyadic) is a 2nd order tensor formed from the direct product of 2 vectors. The dyadic $\svec{u}\svec{v}$ is defined such that the action of this tensor on a vector $\svec{w}$ is:
\begin{equation}\laeq{def:dyad}
  \svec{u}\svec{v} (\svec{w}) = \svec{u}(\svec{v} \cdot \svec{w})
\end{equation}
The Cartesian components are ${(\svec{u}\svec{v})}_{\alpha, \gamma} = u_{\alpha}v_{\gamma} $ or
\[
  \svec{u}\svec{v} = 
  \begin{pmatrix}
    u_1 v_1 & u_1 v_2 & u_1 v_3 \\
    u_2 v_1 & u_2 v_2 & u_2 v_3 \\
    u_3 v_1 & u_3 v_2 & u_3 v_3
  \end{pmatrix}
\]
Given a unit vector, $\hat{u}$, the definition in \refeq{def:dyad}, makes it easy to construct an operator which projects another vector onto $\hat{u}$. For example:
\begin{align}
  \hat{u}\hat{u}(\svec{w}) = \hat{u} (\hat{u} \cdot \svec{w}) = {\textrm{Proj}}_{\hat{u}} \svec{w}
\end{align}
gives the projection of $\svec{w}$ on $\hat{u}$. See Figure~\ref{fig:proj} for a geometric interpretation.

\begin{figure}[h]
  \centering % unlike \begin{center}... does not add white-space padding
    \includegraphics[width=.5\textwidth]{simmonds1982}
  \caption{\label{fig:proj}Geometric realization of the projection of $\svec{w}$ onto $\hat{u}$. Modified from~\cite{simmonds:1982}.}
\end{figure}

A useful property of projection operators is their \emph{idempotence}. From the geometric significance, it must follow that repeat application of any projection, is equivalent to single application. We show that this holds for $\hat{u}\hat{u}$ as follows:
\begin{align}
  {(\hat{u}\hat{u})}^2 &= \hat{u}\hat{u} \; \hat{u}\hat{u} \\
  &= \hat{u} (\hat{u} \cdot \hat{u}) \hat{u}\\
  &= \hat{u}(1)\hat{u} \\
  &= \hat{u}\hat{u}
\end{align}
By induction, we can reason that ${(\hat{u}\hat{u})}^n = \hat{u}\hat{u}$ for all $n \ge 1$.

In addition to projection \emph{on} $\hat{u}$, we can construct the projection \emph{off} of (or orthogonal to) $\hat{u}$. Such a projection is given by:
\begin{equation}
  \left(\mathbbm{1} - \hat{u}\hat{u} \right)
\end{equation}
The orthogonality of the two projections is easily shown:
\begin{align}
  (\mathbbm{1} - \hat{u}\hat{u}) &\hat{u}\hat{u} \\
  = &\hat{u}\hat{u} - {\left( \hat{u}\hat{u} \right)}^2 \\
  = &\hat{u}\hat{u} - \hat{u}\hat{u} \\
  = &0
\end{align}

\paragraph{Armed with such a projection operator,} the analogy to \refeq{NR:parallel} for an \emph{orthogonal} direction is clear. We now take a downhill step and project out all motion along $\hat{\xi}$:
\begin{equation}\laeq{NR:orthogonal}
  (\cvec{R} - \cvec{R}_0) = C \left( \cvec{\mathbbm{1}} - \hat{\xi}\hat{\xi} \right) \cdot \left. \cvec{\nabla} V\right|_{\cvec{R}_0}
\end{equation}
This, we again insert into \refeq{expansion}, yielding:
\begin{align}
  V(\cvec{R}) \approx  V(\cvec{R}_0) + C \left. \cvec{\nabla}V\right|_{\cvec{R}_0} \cdot \left( \cvec{\mathbbm{1}} - \hat{\xi}\hat{\xi} \right) \cdot \left. \cvec{\nabla} V\right|_{\cvec{R}_0} = E_L
\end{align}
Solving for $C$ yields:
\[
  C = \frac{E_L - V(\cvec{R}_0)}{\left. \cvec{\nabla} V\right|_{\cvec{R}_0} \cdot \left( \cvec{\mathbbm{1}} - \hat{\xi}\hat{\xi} \right) \cdot \left. \cvec{\nabla} V\right|_{\cvec{R}_0}}
\]

\paragraph{To enforce a stationary center of mass,} we recall our internal coordinates, \refeq{internalCoors}, which have the following constraints:
\begin{equation}
  \sum_{j=1}^{N}m_j \svec{R}_j = 0
\end{equation}
one for each spatial dimension. We encode these constraints as vector operations in configuration space as:
\begin{align}
  {\left( \cvec{\xi}_{\mu}\right)}_{j\nu} &\equiv \delta_{\mu,\nu} \, m_j\\
  \implies \cvec{\xi}_{\mu} \cdot \cvec{R} &= 0\ \forall\ \mu \in \{x,y,z\}
\end{align}
What does $\cvec{\xi}_{\mu}$ look like? By way of example:
\[
  \cvec{\xi}_{x} =
  \begin{pmatrix}
    m_1    \\
    0      \\
    0      \\
    m_2    \\
    0      \\
    0      \\
    \vdots \\
    m_N    \\
    0      \\
    0      \\
  \end{pmatrix}
\]
The magnitude of $\cvec{\xi}_{\mu}$ is the root of the sum of the squares of the masses:
\begin{equation}
  \left| \cvec{\xi}_{\mu} \right| = \sqrt{\sum_{j=1}^N m_j^2}
\end{equation}
and so the unit vector pointing along $\cvec{\xi}_{\mu}$ is:
\begin{equation}
  {\left( \hat{\xi}_{\mu} \right)}_{j\nu} = \frac{\delta_{\mu,\nu} \, m_j}{\sqrt{\sum_{j=1}^N m_j^2}}
\end{equation}

Constructing the corresponding dyad, we have:
\begin{equation}\laeq{dyad:xixi}
  {\left( \hat{\xi}_{\mu}\hat{\xi}_{\mu} \right)}_{j\gamma,k\alpha} = \frac{m_j m_k}{\sum_{j=1}^N m_j^2}\delta_{\mu,\gamma}\delta_{\mu,\alpha}
\end{equation}
and the projection operator which eliminates center of mass motion along the $\mu$ direction is then:
\begin{align}\laeq{projMu}
  {\left( \cvec{\mathbbm{1}} - \hat{\xi}_{\mu}\hat{\xi}_{\mu} \right)}_{j\gamma,k\alpha}
  &= \delta_{\gamma,\alpha} \delta_{j,k} - \delta_{\mu,\gamma}\delta_{\mu,\alpha} \frac{m_j m_k}{\sum_{j=1}^N m_j^2}  \\
  &= \delta_{\gamma,\alpha} \left(\delta_{j,k} - \delta_{\mu,\gamma}\delta_{\mu,\alpha} \frac{m_j m_k}{\sum_{j=1}^N m_j^2} \right)
\end{align}
Where we have made use of:
\[
  {\left( \cvec{\mathbbm{1}} \right)}_{{j\gamma,k\alpha}} = \delta_{\gamma,\alpha} \delta_{j,k}
\]
and note that in \refeq{projMu}
\[
  \delta_{\gamma,\alpha} \delta_{\mu,\gamma} \delta_{\mu,\alpha} = \delta_{\mu,\gamma} \delta_{\mu,\alpha}
\]
as the term is finite only for $\alpha = \gamma = \mu$ with $\mu$ in the range of $\alpha$ and $\gamma$.

\paragraph{To eliminate center of mass motion along each Cartesian direction,} we form the product of all of them:
\begin{equation}
  \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) \equiv \prod_{\mu} \left( \cvec{\mathbbm{1}} - \hat{\xi}_{\mu}\hat{\xi}_{\mu} \right)
\end{equation}
This product reduces to a sum using the following observation:
\[
  \left( \hat{\xi}_{\mu}\hat{\xi}_{\mu} \right )  \left( \hat{\xi}_{\nu}\hat{\xi}_{\nu} \right ) =   \left( \hat{\xi}_{\mu}\hat{\xi}_{\mu} \right ) \delta_{\mu,\nu}
\]
which is true because $\hat{\xi}_{\mu}$ and $\hat{\xi}_{\nu}$ are orthogonal. This leaves:
\begin{equation}
  \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) = \left( \cvec{\mathbbm{1}} - \sum_{\mu} \hat{\xi}_{\mu}\hat{\xi}_{\mu} \right)
\end{equation}
Inserting \refeq{dyad:xixi} and using the same identities we did for \refeq{projMu}, we arrive at:
\begin{equation}\laeq{proj:cm}
  {\left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right)}_{j\gamma,k\alpha} = \delta_{\gamma,\alpha} \left(\delta_{j,k} - \frac{m_j m_k}{\sum_{j=1}^N m_j^2} \right)
\end{equation}
With $\MM \equiv \sum_{j=1}^N m_j^2$ the projection defined by \refeq{proj:cm} has the following symmetric structure in 3 spatial dimensions:
\begin{equation}
  \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) =
  \begin{pmatrix}
    1 - \frac{m_1^2}{\MM} & & & - \frac{m_1 m_2}{\MM} & & &\\
    & 1 - \frac{m_1^2}{\MM} & & & - \frac{m_1 m_2}{\MM} & &\cdots \\
    & & 1 - \frac{m_1^2}{\MM} & & & - \frac{m_1 m_2}{\MM} & \\
    - \frac{m_1 m_2}{\MM} & & & 1 - \frac{m_1^2}{\MM} & & &\\
    & - \frac{m_1 m_2}{\MM} & & & 1 - \frac{m_1^2}{\MM} & &\\
    & & - \frac{m_1 m_2}{\MM} & & & 1 - \frac{m_1^2}{\MM} &\\
    & \vdots & & & & & \ddots
  \end{pmatrix}
\end{equation}

% \begin{equation}
%   \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) = \frac{1}{\MM}
%   \begin{pmatrix}
%     \MM - m_1^2 & & & - m_1 m_2 & & &\\
%     & \MM - m_1^2 & & & - m_1 m_2 & &\cdots \\
%     & & \MM - m_1^2 & & & - m_1 m_2 & \\
%     - m_1 m_2 & & & \MM - m_1^2 & & &\\
%     & - m_1 m_2 & & & \MM - m_1^2 & &\\
%     & & - m_1 m_2 & & & \MM - m_1^2 &\\
%     & \vdots & & & & & \ddots
%   \end{pmatrix}
% \end{equation}

\paragraph{Returning to the  Newton-Raphson problem,} we proceed in analogy to \refeq{NR:orthogonal} and posit that the appropriate solution is to follow the gradient while projecting out center of mass motion:
\begin{equation}\laeq{NR:noCM}
  (\cvec{R} - \cvec{R}_0) = C \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) \cdot \left. \cvec{\nabla} V\right|_{\cvec{R}_0}
\end{equation}
This, we again insert into \refeq{expansion}, yielding:
\begin{align}
  V(\cvec{R}) \approx  V(\cvec{R}_0) + C \left. \cvec{\nabla}V\right|_{\cvec{R}_0} \cdot \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) \cdot \left. \cvec{\nabla} V\right|_{\cvec{R}_0} = E_L
\end{align}
Solving for $C$ yields:
\[
  C = \frac{E_L - V(\cvec{R}_0)}{\left. \cvec{\nabla} V\right|_{\cvec{R}_0} \cdot \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) \cdot \left. \cvec{\nabla} V\right|_{\cvec{R}_0}}
\]
Which we insert back into \refeq{NR:noCM} to find:
\begin{equation}\laeq{dR:noCM}
  (\cvec{R} - \cvec{R}_0) = - \frac{V \left(\cvec{R}_0\right) - E_L}{ {\left| {\left. \cvec{\nabla}'V \right|}_{\cvec{R}_0} \right|}^2} \; {\left. \cvec{\nabla}'V \right|}_{\cvec{R}_0}
\end{equation}
where we have defined $\cvec{\nabla}' \equiv \left( \cvec{\mathbbm{1}} - \cvec{\mathbbm{P}} \right) \cdot \cvec{\nabla}$ as the center-of-mass invariant gradient operator and made use of the idempotent property of projections. 

Applying \refeq{dR:noCM} iteratively leads to the relation (compare to~\cite{wang:2007:geodesics}):
\begin{equation}\laeq{step:escape}
  \cvec{R}_{n+1} = \cvec{R}_{n} -    \frac{V \left(\cvec{R}_n\right) - E_L}{ {\left| {\left. \cvec{\nabla}'V \right|}_{\cvec{R}_n} \right|}^2} \; {\left. \cvec{\nabla}'V \right|}_{\cvec{R}_n}
\end{equation}
where $\cvec{R}_0$ is the first $\cvec{R}^{(t)}$ with $V\left( \cvec{R}^{(t)} \right) > E_L$ from \refeq{step:free}. This procedure will escape the forbidden region while preserving the center of mass.

\bibliography{../bibs/semiclassical,../bibs/general,../bibs/geodesics}
\bibliographystyle{plainnat}

\end{document}